# Chapter 6. Determinants
ç¬¬å…­ç«  è¡Œåˆ—å¼

## 6.1 Motivation and Geometric Meaning
6.1 åŠ¨æœºå’Œå‡ ä½•æ„ä¹‰

Determinants are numerical values associated with square matrices. At first they may appear as a complicated formula, but their importance comes from what they measure: determinants encode scaling, orientation, and invertibility of linear transformations. They bridge algebra and geometry.

è¡Œåˆ—å¼æ˜¯ä¸æ–¹é˜µç›¸å…³çš„æ•°å€¼ã€‚ä¹ä¸€çœ‹ï¼Œå®ƒä»¬å¯èƒ½çœ‹èµ·æ¥åƒä¸€ä¸ªå¤æ‚çš„å…¬å¼ï¼Œä½†å®ƒä»¬çš„é‡è¦æ€§åœ¨äºå®ƒä»¬æ‰€æµ‹é‡çš„å†…å®¹ï¼šè¡Œåˆ—å¼ç¼–ç äº†çº¿æ€§å˜æ¢çš„ç¼©æ”¾ã€æ–¹å‘å’Œå¯é€†æ€§ã€‚å®ƒä»¬è¿æ¥äº†ä»£æ•°å’Œå‡ ä½•ã€‚

### Determinants of 2Ã—2 Matrices
2Ã—2 çŸ©é˜µçš„è¡Œåˆ—å¼

For a 2Ã—2 matrix

å¯¹äº 2Ã—2 çŸ©é˜µ

$$
A = \begin{bmatrix} a & b \\ c & d \end{bmatrix},
$$

the determinant is defined as

è¡Œåˆ—å¼å®šä¹‰ä¸º

$$
\det(A) = ad - bc.
$$

Geometric meaning: If $A$ represents a linear transformation of the plane, then $|\det(A)|$ is the area scaling factor. For example, if $\det(A) = 2$, areas of shapes are doubled. If $\det(A) = 0$, the transformation collapses the plane to a line: all area is lost.

å‡ ä½•å«ä¹‰ï¼šå¦‚æœ $A$ è¡¨ç¤ºå¹³é¢çš„çº¿æ€§å˜æ¢ï¼Œåˆ™ $|\det(A)|$ æ˜¯é¢ç§¯ç¼©æ”¾å› å­ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ $\det(A) = 2$ ï¼Œå½¢çŠ¶çš„é¢ç§¯å°†åŠ å€ã€‚å¦‚æœ $\det(A) = 0$ ï¼Œå˜æ¢å°†å¹³é¢æŠ˜å æˆä¸€æ¡çº¿ï¼šæ‰€æœ‰é¢ç§¯éƒ½å°†ä¸¢å¤±ã€‚

### Determinants of 3Ã—3 Matrices
3Ã—3 çŸ©é˜µçš„è¡Œåˆ—å¼

For

å¯¹äº

$$
A = \begin{bmatrix}a & b & c \\d & e & f \\g & h & i\end{bmatrix},
$$

the determinant can be computed as

è¡Œåˆ—å¼å¯ä»¥è®¡ç®—ä¸º

$$
\det(A) = a(ei - fh) - b(di - fg) + c(dh - eg).
$$

Geometric meaning: In $\mathbb{R}^3$, $|\det(A)|$ is the volume scaling factor. If $\det(A) < 0$, orientation is reversed (a handedness flip), such as turning a right-handed coordinate system into a left-handed one.

å‡ ä½•å«ä¹‰ï¼šåœ¨ $\mathbb{R}^3$ ä¸­ï¼Œ $|\det(A)|$ æ˜¯ä½“ç§¯ç¼©æ”¾å› å­ã€‚å¦‚æœä¸º $\det(A) < 0$ ï¼Œåˆ™æ–¹å‘åè½¬ï¼ˆå³æ‰‹æ€§ç¿»è½¬ï¼‰ï¼Œä¾‹å¦‚å°†å³æ‰‹åæ ‡ç³»è½¬æ¢ä¸ºå·¦æ‰‹åæ ‡ç³»ã€‚

### General Case
ä¸€èˆ¬æƒ…å†µ

For $A \in \mathbb{R}^{n \times n}$, the determinant is a scalar that measures how the linear transformation given by $A$ scales n-dimensional volume.

å¯¹äº $A \in \mathbb{R}^{n \times n}$ ï¼Œè¡Œåˆ—å¼æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå®ƒè¡¡é‡ $A$ ç»™å‡ºçš„çº¿æ€§å˜æ¢å¦‚ä½•ç¼©æ”¾ n ç»´ä½“ç§¯ã€‚

*   If $\det(A) = 0$: the transformation squashes space into a lower dimension, so $A$ is not invertible.

    å¦‚æœ $\det(A) = 0$ ï¼šå˜æ¢å°†ç©ºé—´å‹ç¼©åˆ°è¾ƒä½ç»´åº¦ï¼Œå› æ­¤ $A$ ä¸å¯é€†ã€‚
*   If $\det(A) > 0$: volume is scaled by $\det(A)$, orientation preserved.

    å¦‚æœæ˜¯ $\det(A) > 0$ ï¼šä½“ç§¯æŒ‰ $\det(A)$ ç¼©æ”¾ï¼Œæ–¹å‘ä¿æŒä¸å˜ã€‚
*   If $\det(A) < 0$: volume is scaled by $|\det(A)|$, orientation reversed.

    å¦‚æœæ˜¯ $\det(A) < 0$ ï¼šä½“ç§¯æŒ‰ $|\det(A)|$ ç¼©æ”¾ï¼Œæ–¹å‘åè½¬ã€‚

### Visual Examples
è§†è§‰ç¤ºä¾‹

1.  Shear in $\mathbb{R}^2$: $A = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$. Then $\det(A) = 1$. The transformation slants the unit square into a parallelogram but preserves area.

    $\mathbb{R}^2$ çš„å‰ªåˆ‡ï¼š $A = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$ ã€‚ç„¶åæ˜¯ $\det(A) = 1$ ã€‚å˜æ¢å°†å•ä½æ­£æ–¹å½¢å€¾æ–œä¸ºå¹³è¡Œå››è¾¹å½¢ï¼Œä½†ä¿ç•™é¢ç§¯ã€‚
    
2.  Projection in $\mathbb{R}^2$: $A = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}$. Then $\det(A) = 0$. The unit square collapses into a line segment: area vanishes.

    $\mathbb{R}^2$ ä¸­çš„æŠ•å½±ï¼š $A = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}$ ã€‚ç„¶å $\det(A) = 0$ ã€‚å•ä½æ­£æ–¹å½¢åç¼©æˆä¸€æ¡çº¿æ®µï¼šé¢ç§¯æ¶ˆå¤±ã€‚
    
3.  Rotation in $\mathbb{R}^2$: $R_\theta = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}$. Then $\det(R_\theta) = 1$. Rotations preserve area and orientation.

    $\mathbb{R}^2$ ä¸­çš„æ—‹è½¬ï¼š $R_\theta = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}$ ã€‚ç„¶å $\det(R_\theta) = 1$ ã€‚æ—‹è½¬ä¿ç•™é¢ç§¯å’Œæ–¹å‘ã€‚
    

### Why this matters
ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦

The determinant is not just a formula-it is a measure of transformation. It tells us whether a matrix is invertible, how it distorts space, and whether it flips orientation. This geometric insight makes the determinant indispensable in analysis, geometry, and applied mathematics.

è¡Œåˆ—å¼ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå…¬å¼ï¼Œå®ƒè¿˜æ˜¯ä¸€ç§å˜æ¢çš„åº¦é‡ã€‚å®ƒå‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªçŸ©é˜µæ˜¯å¦å¯é€†ï¼Œå®ƒå¦‚ä½•æ‰­æ›²ç©ºé—´ï¼Œä»¥åŠå®ƒæ˜¯å¦ä¼šç¿»è½¬æ–¹å‘ã€‚è¿™ç§å‡ ä½•å­¦ä¸Šçš„æ´å¯ŸåŠ›ä½¿å¾—è¡Œåˆ—å¼åœ¨åˆ†æã€å‡ ä½•å’Œåº”ç”¨æ•°å­¦ä¸­ä¸å¯æˆ–ç¼ºã€‚

### Exercises 6.1
ç»ƒä¹  6.1

1.  Compute the determinant of

    è®¡ç®—è¡Œåˆ—å¼
$$
\begin{bmatrix} 2 & 3 \\ 1 & 4 \end{bmatrix}
$$

What area scaling factor does it represent? 

å®ƒä»£è¡¨ä»€ä¹ˆé¢ç§¯æ¯”ä¾‹å› å­ï¼Ÿ

2. Find the determinant of the shear matrix

   æ±‚å‰ªåˆ‡çŸ©é˜µçš„è¡Œåˆ—å¼

$$
\begin{bmatrix} 1 & 2 \\ 0 & 1 \end{bmatrix}
$$

What happens to the area of the unit square? 

å•ä½æ­£æ–¹å½¢çš„é¢ç§¯ä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼Ÿ 

3. For the $3 \times 3$ matrix

   å¯¹äº $3 \times 3$ çŸ©é˜µ

$$\begin{bmatrix} 1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 3 \end{bmatrix}$$

Compute the determinant. How does it scale volume in $\mathbb{R}^3$?

è®¡ç®—è¡Œåˆ—å¼ã€‚å®ƒå¦‚ä½•åœ¨$\mathbb{R}^3$ä¸­ç¼©æ”¾ä½“ç§¯ï¼Ÿ

4. Show that any rotation matrix in $\mathbb{R}^2$ has determinant $1$.

   è¯æ˜$\mathbb{R}^2$ä¸­ä»»æ„æ—‹è½¬çŸ©é˜µçš„è¡Œåˆ—å¼å‡ä¸º$1$ã€‚

5. Give an example of a $2 \times 2$ matrix with determinant $-1$. What geometric action does it represent?

   ä¸¾ä¸€ä¸ªè¡Œåˆ—å¼ä¸º$-1$çš„$2 \times 2$çŸ©é˜µçš„ä¾‹å­ã€‚å®ƒä»£è¡¨ä»€ä¹ˆå‡ ä½•ä½œç”¨ï¼Ÿ



## 6.2 Properties of Determinants

è¡Œåˆ—å¼çš„æ€§è´¨

Beyond their geometric meaning, determinants satisfy a collection of algebraic rules that make them powerful tools in linear algebra. These properties allow us to compute efficiently, test invertibility, and understand how determinants behave under matrix operations.

é™¤äº†å‡ ä½•æ„ä¹‰ä¹‹å¤–ï¼Œè¡Œåˆ—å¼è¿˜æ»¡è¶³ä¸€ç³»åˆ—ä»£æ•°è§„åˆ™ï¼Œä½¿å…¶æˆä¸ºçº¿æ€§ä»£æ•°ä¸­å¼ºå¤§çš„å·¥å…·ã€‚è¿™äº›æ€§è´¨ä½¿æˆ‘ä»¬èƒ½å¤Ÿé«˜æ•ˆè®¡ç®—ã€æµ‹è¯•å¯é€†æ€§ï¼Œå¹¶ç†è§£è¡Œåˆ—å¼åœ¨çŸ©â€‹â€‹é˜µè¿ç®—ä¸‹çš„è¡Œä¸ºã€‚

### Basic Properties

åŸºæœ¬å±æ€§

Let $A, B \in \mathbb{R}^{n \times n}$, and let $c \in \mathbb{R}$. Then:

ä»¤ $A, B \in \mathbb{R}^{n \times n}$ ï¼Œä»¤ $c \in \mathbb{R}$ ã€‚åˆ™ï¼š

1.  Identity:

    å•ä½çŸ©é˜µçš„è¡Œåˆ—å¼ä¸º 1ï¼š

$$
\det(I_n) = 1.
$$

2.  Triangular matrices: If $A$ is upper or lower triangular, then

    ä¸‰è§’çŸ©é˜µï¼š å¦‚æœ $A$ æ˜¯ä¸Šä¸‰è§’çŸ©é˜µæˆ–ä¸‹ä¸‰è§’çŸ©é˜µï¼Œåˆ™

$$
\det(A) = a_{11} a_{22} \cdots a_{nn}.
$$

3.  Row/column swap: Interchanging two rows (or columns) multiplies the determinant by $-1$.

    è¡Œ/åˆ—äº¤æ¢ï¼š äº¤æ¢ä¸¤è¡Œï¼ˆæˆ–åˆ—ï¼‰å°†è¡Œåˆ—å¼ä¹˜ä»¥ $-1$ ã€‚
    
4.  Row/column scaling: Multiplying a row (or column) by a scalar $c$ multiplies the determinant by $c$.

    è¡Œ/åˆ—ç¼©æ”¾ï¼š å°†è¡Œï¼ˆæˆ–åˆ—ï¼‰ä¹˜ä»¥æ ‡é‡ $c$ ä¼šå°†è¡Œåˆ—å¼ä¹˜ä»¥ $c$ ã€‚
    
5.  Row/column addition: Adding a multiple of one row to another does not change the determinant.

    è¡Œ/åˆ—åŠ æ³•ï¼šå°†ä¸€è¡Œçš„å€æ•°æ·»åŠ åˆ°å¦ä¸€è¡Œä¸ä¼šæ”¹å˜è¡Œåˆ—å¼ã€‚
    
6.  Transpose:

    è½¬ç½®ï¼š
    

$$
\det(A^T) = \det(A).
$$

7.  Multiplicativity:

    ä¹˜æ³•æ€§ï¼š

$$
\det(AB) = \det(A)\det(B).
$$

8.  Invertibility: $A$ is invertible if and only if $\det(A) \neq 0$.

    å¯é€†æ€§ï¼š å½“ä¸”ä»…å½“ $\det(A) \neq 0$ æ—¶ï¼Œ $A$ æ‰æ˜¯å¯é€†çš„ã€‚

### Example Computations
è®¡ç®—ç¤ºä¾‹

Example 6.2.1. For

ä¾‹ 6.2.1. å¯¹äº

$$
A = \begin{bmatrix}2 & 0 & 0 \\1 & 3 & 0 \\-1 & 4 & 5\end{bmatrix},
$$

$A$ is lower triangular, so

$A$ æ˜¯ä¸‹ä¸‰è§’ï¼Œæ‰€ä»¥

$$
\det(A) = 2 \cdot 3 \cdot 5 = 30.
$$

Example 6.2.2. Let

ä¾‹ 6.2.2. è®¾

$$
B = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}, \quad C = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}.
$$

Then

åˆ™

$$
\det(B) = 1\cdot 4 - 2\cdot 3 = -2, \quad \det(C) = -1.
$$

Since $CB$ is obtained by swapping rows of $B$,

ç”±äº $CB$ æ˜¯é€šè¿‡äº¤æ¢ $B$ çš„è¡Œè·å¾—çš„ï¼Œ

$$
\det(CB) = -\det(B) = 2.
$$

This matches the multiplicativity rule: $\det(CB) = \det(C)\det(B) = (-1)(-2) = 2.$

è¿™ç¬¦åˆä¹˜æ³•è§„åˆ™ï¼š $\det(CB) = \det(C)\det(B) = (-1)(-2) = 2.$

### Geometric Insights
å‡ ä½•æ´å¯Ÿ

*   Row swaps: flipping orientation of space.

    è¡Œäº¤æ¢ï¼šç¿»è½¬ç©ºé—´çš„æ–¹å‘ã€‚
*   Scaling a row: stretching space in one direction.

    ç¼©æ”¾ä¸€è¡Œï¼šæœä¸€ä¸ªæ–¹å‘æ‹‰ä¼¸ç©ºé—´ã€‚
*   Row replacement: sliding hyperplanes without altering volume.

    è¡Œæ›¿æ¢ï¼šæ»‘åŠ¨è¶…å¹³é¢è€Œä¸æ”¹å˜ä½“ç§¯ã€‚
*   Multiplicativity: performing two transformations multiplies their scaling factors.

    ä¹˜æ³•æ€§ï¼šæ‰§è¡Œä¸¤ä¸ªå˜æ¢ä¼šå°†å®ƒä»¬çš„æ¯”ä¾‹å› å­ç›¸ä¹˜ã€‚

These properties make determinants both computationally manageable and geometrically interpretable.

è¿™äº›æ€§è´¨ä½¿å¾—è¡Œåˆ—å¼æ—¢æ˜“äºè®¡ç®—ç®¡ç†ï¼Œåˆæ˜“äºå‡ ä½•è§£é‡Šã€‚

### Why this matters
ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦

Determinant properties connect computation with geometry and theory. They explain why Gaussian elimination works, why invertibility is equivalent to nonzero determinant, and why determinants naturally arise in areas like volume computation, eigenvalue theory, and differential equations.
è¡Œåˆ—å¼çš„æ€§è´¨å°†è®¡ç®—ä¸å‡ ä½•å’Œç†è®ºè”ç³»èµ·æ¥ã€‚å®ƒä»¬è§£é‡Šäº†é«˜æ–¯æ¶ˆå…ƒæ³•ä¸ºä½•æœ‰æ•ˆï¼Œå¯é€†æ€§ä¸ºä½•ç­‰ä»·äºéé›¶è¡Œåˆ—å¼ï¼Œä»¥åŠè¡Œåˆ—å¼ä¸ºä½•è‡ªç„¶åœ°å‡ºç°åœ¨ä½“ç§¯è®¡ç®—ã€ç‰¹å¾å€¼ç†è®ºå’Œå¾®åˆ†æ–¹ç¨‹ç­‰é¢†åŸŸã€‚

### Exercises 6.2
ç»ƒä¹  6.2

1.  Compute the determinant of
    è®¡ç®—è¡Œåˆ—å¼

$$
A = \begin{bmatrix} 1 & 2 & 3 \\ 0 & 1 & 4 \\ 0 & 0 & 2 \end{bmatrix}.
$$

2.  Show that if two rows of a square matrix are identical, then its determinant is zero.
    è¯æ˜å¦‚æœæ–¹é˜µçš„ä¸¤è¡Œç›¸åŒï¼Œåˆ™å…¶è¡Œåˆ—å¼ä¸ºé›¶ã€‚
    
3.  Verify $\det(A^T) = \det(A)$ for
    éªŒè¯ $\det(A^T) = \det(A)$
    

$$
A = \begin{bmatrix} 2 & -1 \\ 3 & 4 \end{bmatrix}.
$$

4.  If $A$ is invertible, prove that
    å¦‚æœ $A$ å¯é€†ï¼Œåˆ™è¯æ˜

$$
\det(A^{-1}) = \frac{1}{\det(A)}.
$$

5.  Suppose $A$ is a $3\\times 3$matrix with$\\det(A) = 5$. What is $\\det(2A)$?
    å‡è®¾ $A$ æ˜¯ $3\\times 3 $matrix with$ \\det(A) = 5 $. What is $ \\det(2A)$ï¼Ÿ

## 6.3 Cofactor Expansion
6.3 è¾…å› å­å±•å¼€

While determinants of small matrices can be computed directly from formulas, larger matrices require a systematic method. The cofactor expansion (also known as Laplace expansion) provides a recursive way to compute determinants by breaking them into smaller ones.
è™½ç„¶å°çŸ©é˜µçš„è¡Œåˆ—å¼å¯ä»¥ç›´æ¥é€šè¿‡å…¬å¼è®¡ç®—ï¼Œä½†è¾ƒå¤§çš„çŸ©é˜µåˆ™éœ€è¦ç³»ç»Ÿçš„æ–¹æ³•ã€‚ä½™å› å­å±•å¼€å¼ï¼ˆä¹Ÿç§°ä¸ºæ‹‰æ™®æ‹‰æ–¯å±•å¼€å¼ï¼‰é€šè¿‡å°†è¡Œåˆ—å¼åˆ†è§£ä¸ºæ›´å°çš„çŸ©é˜µï¼Œæä¾›äº†ä¸€ç§é€’å½’è®¡ç®—è¡Œåˆ—å¼çš„æ–¹æ³•ã€‚

### Minors and Cofactors
å°å¼å’Œè¾…å› å­

For an $n \times n$ matrix $A = [a_{ij}]$:
å¯¹äº $n \times n$ çŸ©é˜µ $A = [a_{ij}]$ ï¼š

*   The minor $M_{ij}$ is the determinant of the $(n-1) \times (n-1)$ matrix obtained by deleting the $i$\-th row and $j$ -th column of $A$.
    å°è°ƒğ‘€ ğ‘– ğ‘— M ä¼Šå¥‡ â€‹ æ˜¯åˆ é™¤ç¬¬ $i$ è¡Œå’Œ $j$ åå¾—åˆ°çš„ $(n-1) \times (n-1)$ çŸ©é˜µçš„è¡Œåˆ—å¼ $A$ çš„ç¬¬åˆ—ã€‚
*   The cofactor $C_{ij}$ is defined by
    è¾…å› å­ğ¶ ğ‘– ğ‘— C ä¼Šå¥‡ â€‹ å®šä¹‰ä¸º

$$
C_{ij} = (-1)^{i+j} M_{ij}.
$$

The sign factor $(-1)^{i+j}$ alternates in a checkerboard pattern:
ç¬¦å·å› å­ $(-1)^{i+j}$ ä»¥æ£‹ç›˜æ ¼å›¾æ¡ˆäº¤æ›¿å‡ºç°ï¼š

$$
\begin{bmatrix}+ & - & + & - & \cdots \\- & + & - & + & \cdots \\+ & - & + & - & \cdots \\\vdots & \vdots & \vdots & \vdots & \ddots\end{bmatrix}.
$$

### Cofactor Expansion Formula
è¾…å› å¼å±•å¼€å…¬å¼

The determinant of $A$ can be computed by expanding along any row or any column:
$A$ çš„è¡Œåˆ—å¼å¯ä»¥é€šè¿‡æ²¿ä»»æ„è¡Œæˆ–ä»»æ„åˆ—å±•å¼€æ¥è®¡ç®—ï¼š

$$
\det(A) = \sum_{j=1}^n a_{ij} C_{ij} \quad \text{(expansion along row \(i\))},
$$

 

$$
\det(A) = \sum_{i=1}^n a_{ij} C_{ij} \quad \text{(expansion along column \(j\))}.
$$

### Example
ä¾‹å­

Example 6.3.1. Compute
ä¾‹ 6.3.1. è®¡ç®—

$$
A = \begin{bmatrix}1 & 2 & 3 \\0 & 4 & 5 \\1 & 0 & 6\end{bmatrix}.
$$

Expand along the first row:
æ²¿ç¬¬ä¸€è¡Œå±•å¼€ï¼š

$$
\det(A) = 1 \cdot C_{11} + 2 \cdot C_{12} + 3 \cdot C_{13}.
$$

*   For $C_{11}$:
    å¯¹äºğ¶ 11 C 11 â€‹ :

$$
M_{11} = \det \begin{bmatrix} 4 & 5 \\ 0 & 6 \end{bmatrix} = 24
$$

so $C_{11} = (+1)(24) = 24$.
æ‰€ä»¥ $C_{11} = (+1)(24) = 24$ ã€‚

*   For $C_{12}$:
    å¯¹äºğ¶ 12 C 12 â€‹ :

$$
M_{12} = \det \begin{bmatrix} 0 & 5 \\ 1 & 6 \end{bmatrix} = 0 - 5 = -5
$$

so $C_{12} = (-1)(-5) = 5$.
æ‰€ä»¥ $C_{12} = (-1)(-5) = 5$ ã€‚

*   For $C_{13}$:
    å¯¹äºğ¶ 13 C 13 â€‹ :

$$
M_{13} = \det \begin{bmatrix} 0 & 4 \\ 1 & 0 \end{bmatrix} = 0 - 4 = -4
$$

so $C_{13} = (+1)(-4) = -4$.
æ‰€ä»¥ $C_{13} = (+1)(-4) = -4$ ã€‚

Thus,
å› æ­¤ï¼Œ

$$
\det(A) = 1(24) + 2(5) + 3(-4) = 24 + 10 - 12 = 22.
$$

### Properties of Cofactor Expansion
è¾…å› å­å±•å¼€çš„æ€§è´¨

1.  Expansion along any row or column yields the same result.
    æ²¿ä»»æ„è¡Œæˆ–åˆ—æ‰©å±•éƒ½ä¼šäº§ç”Ÿç›¸åŒçš„ç»“æœã€‚
2.  The cofactor expansion provides a recursive definition of determinant: a determinant of size $n$ is expressed in terms of determinants of size $n-1$.
    ä½™å› å­å±•å¼€æä¾›äº†è¡Œåˆ—å¼çš„é€’å½’å®šä¹‰ï¼šå¤§å°ä¸º $n$ çš„è¡Œåˆ—å¼å¯ä»¥ç”¨å¤§å°ä¸º $n-1$ çš„è¡Œåˆ—å¼æ¥è¡¨ç¤ºã€‚
3.  Cofactors are fundamental in constructing the adjugate matrix, which gives a formula for inverses:
    ä½™å› å­æ˜¯æ„é€ ä¼´éšçŸ©é˜µçš„åŸºç¡€ï¼Œå®ƒç»™å‡ºäº†é€†çš„å…¬å¼ï¼š

$$
A^{-1} = \frac{1}{\det(A)} \, \text{adj}(A), \quad \text{where adj}(A) = [C_{ji}].
$$

### Geometric Interpretation
å‡ ä½•è§£é‡Š

Cofactor expansion breaks down the determinant into contributions from sub-volumes defined by fixing one row or column at a time. Each cofactor measures how that row/column influences the overall volume scaling.
ä½™å› å­å±•å¼€å°†è¡Œåˆ—å¼åˆ†è§£ä¸ºç”±æ¯æ¬¡å›ºå®šä¸€è¡Œæˆ–ä¸€åˆ—å®šä¹‰çš„å­ä½“ç§¯çš„è´¡çŒ®ã€‚æ¯ä¸ªä½™å› å­è¡¡é‡è¯¥è¡Œ/åˆ—å¯¹æ•´ä½“ä½“ç§¯ç¼©æ”¾çš„å½±å“ã€‚

### Why this matters
ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦

Cofactor expansion generalizes the small-matrix formulas and provides a conceptual definition of determinants. While not the most efficient way to compute determinants for large matrices, it is essential for theory, proofs, and connections to adjugates, Cramerâ€™s rule, and classical geometry.
ä½™å› å­å±•å¼€å¼æ¨å¹¿äº†å°çŸ©é˜µå…¬å¼ï¼Œå¹¶æä¾›äº†è¡Œåˆ—å¼çš„æ¦‚å¿µå®šä¹‰ã€‚è™½ç„¶å®ƒå¹¶éè®¡ç®—å¤§çŸ©é˜µè¡Œåˆ—å¼çš„æœ€æœ‰æ•ˆæ–¹æ³•ï¼Œä½†å®ƒå¯¹äºç†è®ºã€è¯æ˜ä»¥åŠä¸ä¼´éšé¡¹ã€å…‹è±å§†è§„åˆ™å’Œå¤å…¸å‡ ä½•çš„è”ç³»è‡³å…³é‡è¦ã€‚

### Exercises 6.3
ç»ƒä¹  6.3

1.  Compute the determinant of
    è®¡ç®—è¡Œåˆ—å¼

$$
\begin{bmatrix}2 & 0 & 1 \\3 & -1 & 4 \\1 & 2 & 0\end{bmatrix}
$$

by cofactor expansion along the first column.
é€šè¿‡æ²¿ç¬¬ä¸€åˆ—çš„ä½™å› å­å±•å¼€ã€‚

2.  Verify that expanding along the second row of Example 6.3.1 gives the same determinant.
    éªŒè¯æ²¿ç¤ºä¾‹ 6.3.1 çš„ç¬¬äºŒè¡Œå±•å¼€æ˜¯å¦ç»™å‡ºç›¸åŒçš„è¡Œåˆ—å¼ã€‚
    
3.  Prove that expansion along any row gives the same value.
    è¯æ˜æ²¿ä»»ä½•è¡Œå±•å¼€éƒ½ä¼šç»™å‡ºç›¸åŒçš„å€¼ã€‚
    
4.  Show that if a row of a matrix is zero, then its determinant is zero.
    è¯æ˜å¦‚æœçŸ©é˜µçš„æŸä¸€è¡Œæ˜¯é›¶ï¼Œé‚£ä¹ˆå®ƒçš„è¡Œåˆ—å¼ä¹Ÿæ˜¯é›¶ã€‚
    
5.  Use cofactor expansion to prove that $\det(A) = \det(A^T)$.
    ä½¿ç”¨ä½™å› å­å±•å¼€æ¥è¯æ˜ $\det(A) = \det(A^T)$ ã€‚
    

## 6.4 Applications (Volume, Invertibility Test)
6.4 åº”ç”¨ï¼ˆä½“ç§¯ã€å¯é€†æ€§æµ‹è¯•ï¼‰

Determinants are not merely algebraic curiosities; they have concrete geometric and computational uses. Two of the most important applications are measuring volumes and testing invertibility of matrices.
è¡Œåˆ—å¼ä¸ä»…ä»…æ˜¯ä»£æ•°ä¸Šçš„å¥‡é—»ï¼›å®ƒä»¬æœ‰ç€å…·ä½“çš„å‡ ä½•å’Œè®¡ç®—ç”¨é€”ã€‚å…¶ä¸­æœ€é‡è¦çš„ä¸¤ä¸ªåº”ç”¨æ˜¯æµ‹é‡ä½“ç§¯å’Œæ£€éªŒçŸ©é˜µçš„å¯é€†æ€§ã€‚

### Determinants as Volume Scalers
å†³å®šå› ç´ ä½œä¸ºä½“ç§¯æ ‡é‡

Given vectors $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n \in \mathbb{R}^n$, arrange them as columns of a matrix:
ç»™å®šå‘é‡ $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n \in \mathbb{R}^n$ ï¼Œå°†å®ƒä»¬æ’åˆ—ä¸ºçŸ©é˜µçš„åˆ—ï¼š

$$
A = \begin{bmatrix}| & | & & | \\\mathbf{v}_1 & \mathbf{v}_2 & \cdots & \mathbf{v}_n \\| & | & & |\end{bmatrix}.
$$

Then $|\det(A)|$ equals the volume of the parallelepiped spanned by these vectors.
é‚£ä¹ˆ $|\det(A)|$ ç­‰äºè¿™äº›å‘é‡æ‰€è·¨è¶Šçš„å¹³è¡Œå…­é¢ä½“çš„ä½“ç§¯ã€‚

*   In $\mathbb{R}^2$, $|\det(A)|$ gives the area of the parallelogram spanned by $\mathbf{v}_1, \mathbf{v}_2$.
    åœ¨ $\mathbb{R}^2$ ä¸­ï¼Œ $|\det(A)|$ ç»™å‡ºç”± ğ‘£ æ„æˆçš„å¹³è¡Œå››è¾¹å½¢çš„é¢ç§¯ 1 , ğ‘£ 2 v 1 â€‹ ï¼Œv 2 â€‹ .
*   In $\mathbb{R}^3$, $|\det(A)|$ gives the volume of the parallelepiped spanned by $\mathbf{v}_1, \mathbf{v}_2, \mathbf{v}_3$.
    åœ¨ $\mathbb{R}^3$ ä¸­ï¼Œ $|\det(A)|$ ç»™å‡ºå¹³è¡Œå…­é¢ä½“çš„ä½“ç§¯ï¼Œè·¨åº¦ä¸º ğ‘£ 1 , ğ‘£ 2 , ğ‘£ 3 v 1 â€‹ ï¼Œv 2 â€‹ ï¼Œv 3 â€‹ .
*   In higher dimensions, it generalizes to $n$\-dimensional volume (hypervolume).
    åœ¨æ›´é«˜ç»´åº¦ä¸­ï¼Œå®ƒå¯ä»¥æ¨å¹¿åˆ° $n$ ç»´ä½“ç§¯ï¼ˆè¶…ä½“ç§¯ï¼‰ã€‚

Example 6.4.1. Let
ä¾‹ 6.4.1. è®¾

$$
\mathbf{v}_1 = (1,0,0), \quad \mathbf{v}_2 = (1,1,0), \quad \mathbf{v}_3 = (1,1,1).
$$

Then
ç„¶å

$$
A = \begin{bmatrix}1 & 1 & 1 \\0 & 1 & 1 \\0 & 0 & 1\end{bmatrix}, \quad \det(A) = 1.
$$

So the parallelepiped has volume 1, even though the vectors are not orthogonal.
å› æ­¤ï¼Œå³ä½¿å‘é‡ä¸æ­£äº¤ï¼Œå¹³è¡Œå…­é¢ä½“çš„ä½“ç§¯ä¹Ÿæ˜¯ 1 ã€‚

### Invertibility Test
å¯é€†æ€§æµ‹è¯•

A square matrix $A$ is invertible if and only if $\det(A) \neq 0$.
æ–¹é˜µ $A$ å¯é€†å½“ä¸”ä»…å½“ $\det(A) \neq 0$ ã€‚

*   If $\det(A) = 0$: the transformation collapses space into a lower dimension (area/volume is zero). No inverse exists.
    å¦‚æœ $\det(A) = 0$ ï¼šå˜æ¢å°†ç©ºé—´å¡Œç¼©è‡³è¾ƒä½ç»´åº¦ï¼ˆé¢ç§¯/ä½“ç§¯ä¸ºé›¶ï¼‰ã€‚ä¸å­˜åœ¨é€†å˜æ¢ã€‚
*   If $\det(A) \neq 0$: the transformation scales volume by $|\det(A)|$, and is reversible.
    å¦‚æœ $\det(A) \neq 0$ ï¼šå˜æ¢å°†ä½“ç§¯ç¼©æ”¾ $|\det(A)|$ ï¼Œå¹¶ä¸”æ˜¯å¯é€†çš„ã€‚

Example 6.4.2. The matrix
ä¾‹ 6.4.2. çŸ©é˜µ

$$
B = \begin{bmatrix} 2 & 4 \\ 1 & 2 \end{bmatrix}
$$

has determinant $\det(B) = 2 \cdot 2 - 4 \cdot 1 = 0$. Thus, $B$ is not invertible. Geometrically, the two column vectors are collinear, spanning only a line in $\mathbb{R}^2$.
è¡Œåˆ—å¼ä¸º $\det(B) = 2 \cdot 2 - 4 \cdot 1 = 0$ ã€‚å› æ­¤ï¼Œ $B$ ä¸å¯é€†ã€‚å‡ ä½•ä¸Šï¼Œè¿™ä¸¤ä¸ªåˆ—å‘é‡å…±çº¿ï¼Œåœ¨ $\mathbb{R}^2$ ä¸­ä»…å»¶ä¼¸ä¸€æ¡çº¿ã€‚

### Cramerâ€™s Rule
å…‹è±é»˜è§„åˆ™

Determinants also provide an explicit formula for solving systems of linear equations when the matrix is invertible. For $A\mathbf{x} = \mathbf{b}$ with $A \in \mathbb{R}^{n \times n}$:
å½“çŸ©é˜µå¯é€†æ—¶ï¼Œè¡Œåˆ—å¼è¿˜æä¾›äº†æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„çš„æ˜ç¡®å…¬å¼ã€‚ å¯¹äºå¸¦æœ‰ $A \in \mathbb{R}^{n \times n}$ çš„ $A\mathbf{x} = \mathbf{b}$ ï¼š

$$
x_i = \frac{\det(A_i)}{\det(A)},
$$

where $A_i$ is obtained by replacing the $i$\-th column of $A$ with $\mathbf{b}$. While inefficient computationally, Cramerâ€™s rule highlights the determinantâ€™s role in solutions and uniqueness.
å…¶ä¸­ğ´ ğ‘– A i â€‹ é€šè¿‡å°† $A$ çš„ç¬¬ $i$ åˆ—æ›¿æ¢ä¸º $\mathbf{b}$ å¾—åˆ°ã€‚å…‹è±å§†è§„åˆ™è™½ç„¶è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œä½†å®ƒå‡¸æ˜¾äº†è¡Œåˆ—å¼åœ¨è§£å’Œå”¯ä¸€æ€§æ–¹é¢çš„ä½œç”¨ã€‚

### Orientation
æ–¹å‘

The sign of $\det(A)$ indicates whether a transformation preserves or reverses orientation. For example, a reflection in the plane has determinant $-1$, flipping handedness.
$\det(A)$ çš„ç¬¦å·è¡¨ç¤ºå˜æ¢æ˜¯ä¿æŒæ–¹å‘è¿˜æ˜¯åè½¬æ–¹å‘ã€‚ä¾‹å¦‚ï¼Œå¹³é¢ä¸Šçš„åå°„å…·æœ‰è¡Œåˆ—å¼ $-1$ ï¼Œå³ç¿»è½¬æ—‹å‘æ€§ã€‚

### Why this matters
ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦

Determinants condense key information: they measure scaling, test invertibility, and track orientation. These insights are indispensable in geometry (areas and volumes), analysis (Jacobian determinants in calculus), and computation ( solving systems and checking singularity).
è¡Œåˆ—å¼æµ“ç¼©äº†å…³é”®ä¿¡æ¯ï¼šå®ƒä»¬æµ‹é‡ç¼©æ”¾æ¯”ä¾‹ã€æ£€éªŒå¯é€†æ€§å¹¶è¿½è¸ªæ–¹å‘ã€‚è¿™äº›æ´è§åœ¨å‡ ä½•å­¦ï¼ˆé¢ç§¯å’Œä½“ç§¯ï¼‰ã€åˆ†æå­¦ï¼ˆå¾®ç§¯åˆ†ä¸­çš„é›…å¯æ¯”è¡Œåˆ—å¼ï¼‰å’Œè®¡ç®—å­¦ï¼ˆæ±‚è§£ç³»ç»Ÿå’Œæ£€æŸ¥å¥‡ç‚¹ï¼‰ä¸­éƒ½ä¸å¯æˆ–ç¼ºã€‚

### Exercises 6.4
ç»ƒä¹  6.4

1.  Compute the area of the parallelogram spanned by $(2,1)$ and $(1,3)$.
    è®¡ç®— $(2,1)$ å’Œ $(1,3)$ æ‰€æ„æˆçš„å¹³è¡Œå››è¾¹å½¢çš„é¢ç§¯ã€‚
    
2.  Find the volume of the parallelepiped spanned by $(1,0,0), (1,1,0), (1,1,1)$.
    æ±‚å‡º $(1,0,0), (1,1,0), (1,1,1)$ æ‰€è·¨åº¦çš„å¹³è¡Œå…­é¢ä½“çš„ä½“ç§¯ã€‚
    
3.  Determine whether the matrix
    ç¡®å®šçŸ©é˜µ
    

$$
\begin{bmatrix} 1 & 2 \\ 3 & 6 \end{bmatrix}
$$

is invertible. Justify using determinants. 4. Use Cramerâ€™s rule to solve
æ˜¯å¯é€†çš„ã€‚ç”¨è¡Œåˆ—å¼è¯æ˜ã€‚4. ä½¿ç”¨å…‹è±å§†è§„åˆ™æ±‚è§£

$$
\begin{cases}x + y = 3, \\2x - y = 0.\end{cases}
$$

5.  Explain geometrically why a determinant of zero implies no inverse exists.
    ä»å‡ ä½•è§’åº¦è§£é‡Šä¸ºä»€ä¹ˆè¡Œåˆ—å¼ä¸ºé›¶æ„å‘³ç€ä¸å­˜åœ¨é€†å…ƒã€‚